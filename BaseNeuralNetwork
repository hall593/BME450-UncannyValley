import os
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from torchvision.io import read_image
from PIL import Image
import torchvision.transforms as transforms


tdataPath = r"C:/Users/macke/Desktop/450 Dataset/Training" # Change to specific file path for training data folder 
tlabels = os.path.join(tdataPath, 'Labelled Data.csv') # label path for training
vdataPath = r"C:/Users/macke/Desktop/450 Dataset/Validation" # Change to specific file path for validation data folder 
vlabels = os.path.join(vdataPath, 'Labelled Data.csv') # label path for validation

# Preparation of Dataset WORKS

class CustomDataset(Dataset):
    # identifying
    def __init__(self, labels, imgDirectory, transform = None, target_transform = None):
        # Initializaation
        self.labels =  pd.read_csv(labels)
        self.imgDirectory = imgDirectory 
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        # Denotes total num of samples
        return len(self.labels)
    
    def __getitem__(self, index):
        # Generates one samples of data
        img_path = os.path.join(self.imgDirectory, self.labels.iloc[index, 0]) # error here 
        # above function works by joining path and image name for location
        image = read_image(img_path)
        imglabel = self.labels.iloc[index, 1] # reads second column for designated label

        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            imglabel = self.target_transform(imglabel)
        return image, imglabel

def expand2square(pil_img, background_color):
    width, height = pil_img.size
    if width == height:
        return pil_img
    elif width > height:
        result = Image.new(pil_img.mode, (width, width), background_color)
        result.paste(pil_img, (0, (width - height) // 2))
        return result
    else:
        result = Image.new(pil_img.mode, (height, height), background_color)
        result.paste(pil_img, ((height - width) // 2, 0))
        return result
    

class Rescale:
    def __init__(self, sizing = 200): 
        # if the sizing value is changed, values in Net() __init__ need to be changed for matrix multiplication
        self.sizing = sizing

    def __call__(self, tensor):
        toPIL = transforms.ToPILImage()(tensor) # converts tensor to image
        toPIL = toPIL.convert(mode='RGB') # ensures all pictures have same color channel
        toPIL.thumbnail((self.sizing, self.sizing)) # not sure if need, resizes keeping aspect ratio 
        resized = expand2square(toPIL, (0, 0, 0)).resize((self.sizing, self.sizing)) # adds padding and resizes again         
        newTen = transforms.ToTensor()(resized) # converts back to tensor
        return newTen


batch_size = 5 # Change!!!!, batch size seems to actually icnrease accuracy for training, had it at 20 earlier

# Preparaing datasets
train_dataset = CustomDataset(tlabels, tdataPath, transform=Rescale())
train_dataloader = DataLoader(train_dataset, batch_size, shuffle = True)

valid_dataset = CustomDataset(vlabels, vdataPath, transform=Rescale())
valid_dataloader = DataLoader(valid_dataset, batch_size, shuffle = True)


# INITIALIZATION OF NEURAL NETWORK
import torch.nn as nn
import torch.nn.functional as F
import torch

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(35344, 10)
        self.fc2 = nn.Linear(10, 10)
        self.fc3 = nn.Linear(10, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()

# try different optimizer, what is criterion? 
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)


# plotting loss with just training, comment out if want to validate

num_epoch = 5
'''
t_loss = []
batch = []

avg = 0
avg_counter = 0
for epoch in range(num_epoch):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(train_dataloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        
        if i % 5 == 4:   
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 5:.3f}')
            avg += running_loss
            running_loss = 0.0
        avg_counter += 1
    t_loss.append(avg/avg_counter)
    batch.append(epoch)
    avg = 0
    avg_counter = 0
'''

import matplotlib.pyplot as plt
import numpy as np

'''
print('Finished Training')
x = np.array(batch)
y = np.array(t_loss)
plt.plot(x, y)
plt.xlabel('Epoch')
plt.xlim([0, num_epoch])
plt.ylabel('Loss')
plt.title('Training Loss')
plt.show()
'''


PATH = './cifar_net.pth' 
# Saving model, uncomment if training
#torch.save(net.state_dict(), PATH)

# Loading model, uncomment if validating
net.load_state_dict(torch.load(PATH))

labels_map = { # can change to more extensive cateogorization if enough time, starting off with binary now
    0: "Not Uncanny",
    1: "Uncanny"
}

correct = 0
total = 0

# counting predictions for each class
correct_pred = {classname: 0 for classname in labels_map}
total_pred = {classname: 0 for classname in labels_map}

trainingEpoch_loss = []
validationEpoch_loss = []

for epoch in range(num_epoch):
    step_loss = []
    for i, data in enumerate(train_dataloader):
        inputs, labels = data
         
        # Clear the gradients
        optimizer.zero_grad()
        # Forward Pass
        outputs = net(inputs)
        # Find the Loss
        training_loss = criterion(outputs, labels)
        # Calculate gradients
        training_loss.backward()
        # Update Weights
        optimizer.step()

        # Calculate Loss
        step_loss.append(training_loss.item())
        if (i+1) % 1 == 0:
            print (f'Epoch [{epoch+1}/{num_epoch}] Loss: {training_loss.item():.4f}')
    trainingEpoch_loss.append(np.array(step_loss).mean())
 
    for i, data in enumerate(valid_dataloader):
        index = 0 # printing incorrect 
        validationStep_loss = []
        images, labels = data

        optimizer.zero_grad()
        # Forward Pass
        outputs = net(images)
        _, predictions = torch.max(outputs.data,1)
        # Find the Loss
        loss = criterion(outputs, labels)
        # Calculate Loss
        loss.backward()
        optimizer.step()
        validationStep_loss.append(loss.item())
        
        for label, prediction in zip(labels, predictions):

            if label == prediction:
                correct_pred[torch.IntTensor.item(label)] += 1
            '''
            else:
                test = images[index].permute(1,2,0).numpy() # changes tensor shape to readable image
                plt.imshow(test.squeeze(), cmap = "gray")
                Vdictvalue = torch.IntTensor.item(label) # v_labels returns tensor value, convert to int
                PdictValue = torch.IntTensor.item(prediction)
                print(f"Label: {[labels_map[Vdictvalue]]}")
                print(f"Prediction: {[labels_map[PdictValue]]}")
                plt.show()
            '''
            total_pred[torch.IntTensor.item(label)] += 1
            index += 1
        total += labels.size(0)
        correct += (predictions == labels).sum().item()

    validationEpoch_loss.append(np.array(validationStep_loss).mean())


print(f'Accuracy of the network on the given test images: {100 * correct // total} %')

# print accuracy for each class
for classname, correct_count in correct_pred.items():
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print(f'Accuracy for class: {classname} is {accuracy:.1f} %')

x_epochs = list(range(1, num_epoch + 1))
plt.plot(x_epochs, trainingEpoch_loss, label = "Training Loss")
plt.plot(x_epochs, validationEpoch_loss, label = "Testing Loss")
plt.legend()
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title('Loss per Epoch')
plt.show()
